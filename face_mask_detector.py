# -*- coding: utf-8 -*-
"""face-mask-detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dIrhH4hoM-rOkuAMD5qvzNs15tr9kAwP

# Face Mask Detection

## Problem Statement
Here I am going to detect whether a person is wearing mask or not. I am focussing on only two classes that are 'face_with_mask' and face_no_mask'.

## Datasets
This dataset consists of 1,376 images belonging to with mask and without mask 2 classes.

## Overview
In simple words, First, we get the image with the face and run it through a cascade classifier. The classifier will give the region of interest of the face (height and width). Secondly, we will resize the region of interest into a 100x100 and pass it to a pre-trained CNN, it will give us the probability as an output.

## Data Preprocessing
The dataset we are using consists of images with different colors, different sizes, and different orientations. Therefore, we need to convert all the images into grayscale because we need to be sure that color should not be a critical point for detecting mask. After that, we need to have all the images in the same size (100x100) before applying it to the neural network.
"""

# Import data from drive

from google.colab import drive
drive.mount('/content/drive')

file_path = "drive/MyDrive/face_mask_detector/data"

import cv2,os

img_size=100
data=[]
target=[]
label_dict = {'with_mask': 0, 'without_mask': 1}
categories = ['with_mask', 'without_mask']

for category in categories:
    folder_path=os.path.join(file_path,category)
    img_names=os.listdir(folder_path)
    # print(len(img_names))   
    for img_name in img_names:
        img_path=os.path.join(folder_path,img_name)
        img=cv2.imread(img_path)

        try:
            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  
            #Coverting the image into gray scale       
            resized=cv2.resize(gray,(img_size,img_size))                    
            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset
            data.append(resized)
            target.append(label_dict[category])                                 
            #appending the image and the label(categorized) into the list (dataset)
            

        except Exception as e:
            print('Exception:',e)
            #if any exception rasied, the exception will be printed here. And pass to the next image

import numpy as np

data=np.array(data)/255.0
data=np.reshape(data,(data.shape[0],img_size,img_size,1))
target=np.array(target)

from keras.utils import np_utils

new_target=np_utils.to_categorical(target)

np.save("drive/MyDrive/face_mask_detector/data",data)
np.save("drive/MyDrive/face_mask_detector/target",new_target)

import pandas as pd
from matplotlib import pyplot as plt

plt.bar(['with_mask','without_mask'],pd.DataFrame(target).value_counts())
plt.title('Dataset (mask vs no_mask)')

folder_path=os.path.join(file_path,categories[0])
img_names=os.listdir(folder_path)
img_path=os.path.join(folder_path,img_names[0])
img=plt.imread(img_path)
plt.imshow(img)
plt.show()

import numpy as np

data=np.load('drive/MyDrive/face_mask_detector/data.npy')
target=np.load('drive/MyDrive/face_mask_detector/target.npy')

#loading the save numpy arrays in the previous code

"""## Model (Training the CNN)
This consists of 2 convolutional layers (Two Convo2D 100@3x3). First, you have to load the dataset from data preprocessing. Then you have to configure the convolutional architecture. I’ve included a model.add(Dropout(0.5)) to get rid of overfitting. Since we have two categories(with mask and without mask) we can use binary_crossentropy. You start training for 20 epoch with a model checkpoint.
"""

from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten,Dropout
from keras.layers import Conv2D,MaxPooling2D
from keras.callbacks import ModelCheckpoint

model=Sequential()

model.add(Conv2D(100,(3,3),input_shape=data.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The first CNN layer followed by Relu and MaxPooling layers

model.add(Conv2D(100,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The second convolution layer followed by Relu and MaxPooling layers

model.add(Flatten())
model.add(Dropout(0.5))
#Flatten layer to stack the output convolutions from second convolution layer
model.add(Dense(50,activation='relu'))
#Dense layer of 64 neurons
model.add(Dense(2,activation='softmax'))
#The Final layer with two outputs for two categories

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

from sklearn.model_selection import train_test_split

train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)

checkpoint = ModelCheckpoint('drive/MyDrive/face_mask_detector/model-{epoch:03d}.h5',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')
history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)

# Save the Model


model.save("drive/MyDrive/face_mask_detector/model.model")

# Plot the training loss vs validation loss

from matplotlib import pyplot as plt

plt.plot(history.history['loss'],'r',label='training loss')
plt.plot(history.history['val_loss'],label='validation loss')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

# Plot the training accuracy vs validation accuracy

plt.plot(history.history['accuracy'],'r',label='training accuracy')
plt.plot(history.history['val_accuracy'],label='validation accuracy')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

"""## Model Score"""

print(model.evaluate(test_data,test_target))

"""## Evaluating Model 
Detecting Faces with and without Masks
* load the model that we created. Then we set the camera we want as the default.
* we need to label the two probabilities (0 for with_mask and 1 for without_mask). 
* we need to set the bounding rectangle color using RGB values. I’ve given RED and GREEN as two colors.

Inside an infinite loop, we are going to read frame by frame from the camera and convert them to grayscale and detect the faces. And it will be run through a for loop to for each face and detect the region of interest, resize and reshape it to 4D since the training network expects 4D input.
This result consists of the probability `(result=[P1, P2])` of the with a mask or without a mask. It will be labeled after that.
"""

from keras.models import load_model
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the model

model = load_model('drive/MyDrive/face_mask_detector/model.model')

face_clsfr=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')

source=cv2.VideoCapture('drive/MyDrive/face_mask_detector/test/2.jpg')
labels_dict={0:'with_mask',1:'without_mask'}
color_dict={0:(0,255,0),1:(0,0,255)}

while(True):

    ret,img=source.read()
    img2 = cv2.resize(img, (480, 270))
    cv2_imshow(img2)
    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    faces=face_clsfr.detectMultiScale(gray,1.3,5)  

    for x,y,w,h in faces:
    
        face_img=gray[y:y+w,x:x+w]
        resized=cv2.resize(face_img,(100,100))
        normalized=resized/255.0
        reshaped=np.reshape(normalized,(1,100,100,1))
        result=model.predict(reshaped)

        label=np.argmax(result,axis=1)[0]
      
        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)
        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)
        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)
        
    img1 = cv2.resize(img, (480, 270))
    cv2_imshow(img1)
    key=cv2.waitKey(1)
    
    if(key==27):
        break
        
cv2.destroyAllWindows()
source.release()

